{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c893f4-af52-4d21-9e87-9eb26b4956a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Defining helper functions...\n",
      "\n",
      "Step 1: Loading and preparing datasets...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15999/1682109428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mobjects_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./datasets/objects.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0mconstituents_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./datasets/constituents.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mimages_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./datasets/published_images.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FINAL/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FINAL/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FINAL/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FINAL/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FINAL/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FINAL/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FINAL/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FINAL/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FINAL/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FINAL/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FINAL/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m     \"\"\"\n\u001b[1;32m   1422\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FINAL/lib/python3.7/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/pydev_is_thread_alive.py\u001b[0m in \u001b[0;36mis_thread_alive\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_stopped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3.x has this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mis_thread_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use a non-interactive backend suitable for script running\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # For progress bars\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import faiss\n",
    "\n",
    "# Step 0: Define Helper Functions\n",
    "print(\"Step 0: Defining helper functions...\")\n",
    "\n",
    "def download_images(final_df, save_dir='../../scratch/mexas.v/art_images/*.jpg'):\n",
    "    \"\"\"\n",
    "    Downloads images from URLs specified in the final_df DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - final_df (pd.DataFrame): DataFrame containing 'objectid' and 'image_urls' columns.\n",
    "    - save_dir (str): Directory where images will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"Created directory: {save_dir}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {save_dir}\")\n",
    "\n",
    "    print(\"Starting image downloads...\")\n",
    "    for idx, row in tqdm(final_df.iterrows(), total=final_df.shape[0], desc=\"Downloading images\"):\n",
    "        objectid = str(row['objectid'])\n",
    "        image_urls = row['image_urls']\n",
    "        for i, image_url in enumerate(image_urls):\n",
    "            image_filename = f\"{objectid}_{i}.jpg\"\n",
    "            image_path = os.path.join(save_dir, image_filename)\n",
    "\n",
    "            # Skip downloading if the file already exists\n",
    "            if os.path.exists(image_path):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                response = requests.get(image_url, timeout=10)\n",
    "                response.raise_for_status()  # Check if the request was successful\n",
    "                with open(image_path, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Failed to download {image_filename} from {image_url}: {e}\")\n",
    "\n",
    "def show_results(image_path_or_url, results):\n",
    "    \"\"\"\n",
    "    Displays the query image alongside its top matching results.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path_or_url (str): Path or URL of the query image.\n",
    "    - results (pd.DataFrame): DataFrame containing the top matching artworks.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    print(\"\\nDisplaying results visually...\")\n",
    "    try:\n",
    "        if image_path_or_url.startswith('http'):\n",
    "            response = requests.get(image_path_or_url, timeout=10)\n",
    "            query_img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        else:\n",
    "            query_img = Image.open(image_path_or_url).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load query image: {e}\")\n",
    "        return\n",
    "\n",
    "    num_results = min(len(results), 5)\n",
    "    plt.figure(figsize=(5 * (num_results + 1), 5))\n",
    "\n",
    "    # Display Query Image\n",
    "    plt.subplot(1, num_results + 1, 1)\n",
    "    plt.imshow(query_img)\n",
    "    plt.title('Query Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display Matching Images\n",
    "    for i in range(num_results):\n",
    "        img_path = results.iloc[i]['image_path']\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            plt.subplot(1, num_results + 1, i + 2)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Match {i+1}\")\n",
    "            plt.axis('off')\n",
    "            print(f\"Loaded Match {i+1}: {img_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load image {img_path}: {e}\")\n",
    "\n",
    "    output_dir = 'results'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_path = os.path.join(output_dir, 'query_results.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\"Results displayed and saved to '{output_path}'.\")\n",
    "\n",
    "def process_input_image(image_path_or_url, transform, device):\n",
    "    \"\"\"\n",
    "    Processes the input image by loading, transforming, and sending it to the device.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path_or_url (str): Path or URL of the image.\n",
    "    - transform (torchvision.transforms.Compose): Transformations to apply.\n",
    "    - device (torch.device): Device to send the image tensor.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Processed image tensor.\n",
    "    \"\"\"\n",
    "    print(f\"  Processing input image: {image_path_or_url}\")\n",
    "    try:\n",
    "        if image_path_or_url.startswith('http'):\n",
    "            response = requests.get(image_path_or_url, timeout=10)\n",
    "            img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        else:\n",
    "            img = Image.open(image_path_or_url).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to load image {image_path_or_url}: {e}\")\n",
    "        # Return a black image in case of error\n",
    "        img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "    print(\"  Image processed and transformed.\")\n",
    "    return img\n",
    "\n",
    "def get_image_features(model, img_tensor):\n",
    "    \"\"\"\n",
    "    Extracts and normalizes features from the image tensor.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The feature extraction model.\n",
    "    - img_tensor (torch.Tensor): Image tensor.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Normalized feature vector.\n",
    "    \"\"\"\n",
    "    print(\"  Extracting features from the query image...\")\n",
    "    with torch.no_grad():\n",
    "        features = model(img_tensor)\n",
    "        features = features.view(features.size(0), -1)  # Flatten\n",
    "        features = features / features.norm(dim=1, keepdim=True)\n",
    "    print(\"  Features extracted and normalized.\")\n",
    "    return features.cpu().numpy().astype('float32')\n",
    "\n",
    "def search_artwork(query_features, index, k=5):\n",
    "    \"\"\"\n",
    "    Searches for the top k similar artworks using FAISS.\n",
    "\n",
    "    Parameters:\n",
    "    - query_features (np.ndarray): Feature vector of the query image.\n",
    "    - index (faiss.Index): FAISS index.\n",
    "    - k (int): Number of top matches to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - distances (np.ndarray): Similarity scores.\n",
    "    - indices (np.ndarray): Indices of the top matches.\n",
    "    \"\"\"\n",
    "    print(f\"  Searching for top {k} similar artworks...\")\n",
    "    distances, indices = index.search(query_features, k)\n",
    "    print(\"  Search completed.\")\n",
    "    return distances[0], indices[0]\n",
    "\n",
    "def get_artwork_info(indices, image_df):\n",
    "    \"\"\"\n",
    "    Retrieves artwork information based on the indices.\n",
    "\n",
    "    Parameters:\n",
    "    - indices (np.ndarray): Indices of the top matches.\n",
    "    - image_df (pd.DataFrame): DataFrame containing image metadata.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame of the top matching artworks.\n",
    "    \"\"\"\n",
    "    print(\"  Retrieving artwork information for the top matches...\")\n",
    "    try:\n",
    "        results = image_df.iloc[indices].reset_index(drop=True)\n",
    "        print(\"  Artwork information retrieved.\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error retrieving artwork information: {e}\")\n",
    "        results = pd.DataFrame()  # Return empty DataFrame on error\n",
    "    return results\n",
    "\n",
    "def identify_artwork(image_path_or_url, model, index, image_df, transform, device, k=5):\n",
    "    \"\"\"\n",
    "    Identifies the top k artworks similar to the query image.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path_or_url (str): Path or URL of the query image.\n",
    "    - model (torch.nn.Module): Feature extraction model.\n",
    "    - index (faiss.Index): FAISS index.\n",
    "    - image_df (pd.DataFrame): DataFrame containing image metadata.\n",
    "    - transform (torchvision.transforms.Compose): Transformations to apply.\n",
    "    - device (torch.device): Device to send the image tensor.\n",
    "    - k (int): Number of top matches to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - results (pd.DataFrame): DataFrame of the top matching artworks.\n",
    "    - distances (np.ndarray): Similarity scores.\n",
    "    \"\"\"\n",
    "    print(\"\\nIdentifying artwork...\")\n",
    "    img_tensor = process_input_image(image_path_or_url, transform, device)\n",
    "    query_features = get_image_features(model, img_tensor)\n",
    "    distances, indices = search_artwork(query_features, index, k)\n",
    "    results = get_artwork_info(indices, image_df)\n",
    "    print(\"Artwork identification completed.\")\n",
    "    return results, distances\n",
    "\n",
    "def extract_features(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Extracts features from images using the provided model and dataloader.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The feature extraction model.\n",
    "    - dataloader (DataLoader): DataLoader for the dataset.\n",
    "    - device (torch.device): Device to perform computations on.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Extracted features.\n",
    "    \"\"\"\n",
    "    print(\"Starting feature extraction...\")\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (imgs, _) in enumerate(tqdm(dataloader, desc=\"Extracting features\"), 1):\n",
    "            imgs = imgs.to(device)\n",
    "            try:\n",
    "                outputs = model(imgs)\n",
    "                outputs = outputs.view(outputs.size(0), -1)  # Flatten to (batch_size, feature_dim)\n",
    "                outputs = outputs / outputs.norm(dim=1, keepdim=True)\n",
    "                features.append(outputs.cpu())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch {batch_idx}: {e}\")\n",
    "    features = torch.cat(features, dim=0)\n",
    "    print(\"Feature extraction completed.\")\n",
    "    return features\n",
    "\n",
    "# Step 1: Load and Prepare Datasets\n",
    "print(\"\\nStep 1: Loading and preparing datasets...\")\n",
    "\n",
    "try:\n",
    "    objects_df = pd.read_csv('./datasets/objects.csv')\n",
    "    constituents_df = pd.read_csv('./datasets/constituents.csv')\n",
    "    images_df = pd.read_csv('./datasets/published_images.csv')\n",
    "    print(\"Datasets loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n",
    "    raise\n",
    "\n",
    "# Ensure relevant columns are strings and stripped\n",
    "for df, key in [\n",
    "    (objects_df, 'objectid'),\n",
    "    (constituents_df, 'artistofngaobject'),\n",
    "    (images_df, 'depictstmsobjectid')\n",
    "]:\n",
    "    df[key] = df[key].astype(str).str.strip()\n",
    "\n",
    "# Aggregate artists\n",
    "print(\"Aggregating artist information...\")\n",
    "artists_agg = constituents_df.groupby('artistofngaobject')['preferreddisplayname'] \\\n",
    "    .apply(lambda names: ', '.join(sorted(set(names)))).reset_index()\n",
    "artists_agg.rename(columns={\n",
    "    'artistofngaobject': 'objectid',\n",
    "    'preferreddisplayname': 'artists'\n",
    "}, inplace=True)\n",
    "\n",
    "# Aggregate image URLs\n",
    "print(\"Aggregating image URLs...\")\n",
    "images_agg = images_df.groupby('depictstmsobjectid')['iiifthumburl'] \\\n",
    "    .apply(list).reset_index()\n",
    "images_agg.rename(columns={\n",
    "    'depictstmsobjectid': 'objectid',\n",
    "    'iiifthumburl': 'image_urls'\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge datasets\n",
    "print(\"Merging datasets into final_df...\")\n",
    "merged_with_artists = objects_df.merge(\n",
    "    artists_agg,\n",
    "    on='objectid',\n",
    "    how='left'\n",
    ")\n",
    "final_df = merged_with_artists.merge(\n",
    "    images_agg,\n",
    "    on='objectid',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Select and clean relevant columns\n",
    "final_df = final_df[['objectid', 'title', 'artists', 'image_urls']]\n",
    "final_df['artists'] = final_df['artists'].fillna('Unknown Artist')\n",
    "final_df['image_urls'] = final_df['image_urls'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "final_df = final_df[final_df['image_urls'].map(len) > 0].reset_index(drop=True)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary of final_df:\")\n",
    "print(f\"Unique artworks in objects_df: {objects_df['objectid'].nunique()}\")\n",
    "print(f\"Unique artists in constituents_df: {constituents_df['constituentid'].nunique()}\")\n",
    "print(f\"Unique image URLs in images_df: {images_df['iiifthumburl'].nunique()}\")\n",
    "print(f\"Unique artworks in final_df: {final_df['objectid'].nunique()}\")\n",
    "print(f\"Columns in final_df: {final_df.columns.tolist()}\")\n",
    "\n",
    "# Step 2: Download Images (Optional)\n",
    "# Uncomment the following lines if you need to download images\n",
    "# print(\"\\nStep 2: Downloading images...\")\n",
    "# download_images(final_df)\n",
    "\n",
    "print(\"\\nStep 3: Preparing image_df from downloaded images...\")\n",
    "\n",
    "# Check if 'image_df.pkl' already exists\n",
    "if os.path.exists('image_df.pkl'):\n",
    "    # Load image_df from the pickle file\n",
    "    image_df = pd.read_pickle('image_df.pkl')\n",
    "    print(f\"Loaded image_df with {len(image_df)} entries from 'image_df.pkl'.\")\n",
    "else:\n",
    "    image_paths = glob.glob('../../scratch/mexas.v/art_images/*.jpg')\n",
    "    print(f\"Found {len(image_paths)} images in './art_images/' directory.\")\n",
    "    \n",
    "    # Use all images\n",
    "    subset_image_paths = image_paths\n",
    "    print(f\"Selected {len(subset_image_paths)} images for processing.\")\n",
    "    \n",
    "    # Prepare image_data\n",
    "    image_data = []\n",
    "    for path in tqdm(subset_image_paths, desc=\"Preparing image data\"):\n",
    "        filename = os.path.basename(path)\n",
    "        objectid = filename.split('_')[0]\n",
    "        row = final_df[final_df['objectid'] == objectid]\n",
    "        if row.empty:\n",
    "            # Skip images without metadata\n",
    "            continue\n",
    "        row = row.iloc[0]\n",
    "        image_data.append({\n",
    "            'image_path': path,\n",
    "            'objectid': objectid,\n",
    "            'artists': row['artists'],\n",
    "            'title': row['title']\n",
    "        })\n",
    "    \n",
    "    # Create image_df\n",
    "    image_df = pd.DataFrame(image_data)\n",
    "    print(f\"Prepared image_df with {len(image_df)} entries.\")\n",
    "    \n",
    "    # Save image_df to a pickle file for future use\n",
    "    image_df.to_pickle('image_df.pkl')\n",
    "    print(\"Saved image_df to 'image_df.pkl' for future use.\")\n",
    "\n",
    "# Step 4: Prepare Dataset for Feature Extraction\n",
    "print(\"\\nStep 4: Preparing dataset for feature extraction...\")\n",
    "\n",
    "# No need to filter the dataset since we want to include all images\n",
    "print(f\"Total number of images: {len(image_df)}\")\n",
    "\n",
    "# Step 5: Define Image Transformations\n",
    "print(\"\\nStep 5: Defining image transformations...\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "print(\"Image transformations defined.\")\n",
    "\n",
    "# Step 6: Create Custom Dataset and DataLoader\n",
    "print(\"\\nStep 6: Creating custom dataset and data loader...\")\n",
    "\n",
    "class ArtImageDataset(Dataset):\n",
    "    def __init__(self, image_df, transform=None):\n",
    "        self.image_df = image_df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_df.loc[idx, 'image_path']\n",
    "\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, idx  # Return index to keep track\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "batch_size = 32  # Adjust based on your GPU memory\n",
    "dataset = ArtImageDataset(image_df, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=12)\n",
    "\n",
    "print(f\"DataLoader created with {len(dataloader)} batches.\")\n",
    "\n",
    "# Step 7: Set Up Device and Load Pre-trained Model\n",
    "print(\"\\nStep 7: Setting up the device and loading the pre-trained model...\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the pre-trained ResNet-50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Remove the final classification layer\n",
    "model = nn.Sequential(*list(model.children())[:-1])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Pre-trained model loaded and modified for feature extraction.\")\n",
    "\n",
    "# Step 8: Extract Features\n",
    "print(\"\\nStep 8: Extracting features from all images...\")\n",
    "\n",
    "features = extract_features(model, dataloader, device)\n",
    "print(f\"Extracted features shape: {features.shape}\")\n",
    "\n",
    "# Convert features to numpy array\n",
    "features_np = features.squeeze().numpy().astype('float32')\n",
    "\n",
    "# Save features\n",
    "np.save('image_features.npy', features_np)\n",
    "print(\"Features saved to 'image_features.npy'.\")\n",
    "\n",
    "# Step 9: Create FAISS Index and Add Features\n",
    "print(\"\\nStep 9: Creating FAISS index with extracted features...\")\n",
    "\n",
    "index = faiss.IndexFlatIP(features_np.shape[1])\n",
    "index.add(features_np)\n",
    "faiss.write_index(index, 'faiss_index.bin')\n",
    "print(\"FAISS index created with extracted features and saved to 'faiss_index.bin'.\")\n",
    "\n",
    "# Step 10: Perform the Query on a Sample Image\n",
    "print(\"\\nStep 10: Performing query on a sample image...\")\n",
    "\n",
    "# Use any image from the dataset as the query\n",
    "query_image_index = 80  # Adjust index as needed\n",
    "if query_image_index >= len(image_df):\n",
    "    query_image_index = len(image_df) - 1  # Ensure the index is within range\n",
    "image_to_query = image_df.iloc[query_image_index]['image_path']\n",
    "print(f\"Selected image for querying: {image_to_query}\")\n",
    "\n",
    "try:\n",
    "    # Use the same model and FAISS index\n",
    "    results, distances = identify_artwork(\n",
    "        image_to_query,\n",
    "        model,\n",
    "        index,\n",
    "        image_df,\n",
    "        transform,\n",
    "        device,\n",
    "        k=5\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error identifying artwork: {e}\")\n",
    "    results, distances = None, None\n",
    "\n",
    "# Step 11: Display Top Matching Artworks\n",
    "if results is not None and not results.empty:\n",
    "    print(\"\\nTop matching artworks:\")\n",
    "    for i, (idx, dist) in enumerate(zip(results.index, distances)):\n",
    "        row = results.iloc[i]\n",
    "        print(f\"Rank {i+1}:\")\n",
    "        print(f\"  Artwork Title: {row['title']}\")\n",
    "        print(f\"  Artist: {row['artists']}\")\n",
    "        print(f\"  Similarity Score: {dist:.4f}\")\n",
    "        print(f\"  Image Path: {row['image_path']}\\n\")\n",
    "else:\n",
    "    print(\"No results to display due to an error in identifying the artwork.\")\n",
    "\n",
    "# Step 12: Display Results Visually\n",
    "if results is not None and not results.empty:\n",
    "    print(\"\\nStep 12: Displaying results visually...\")\n",
    "    show_results(image_to_query, results)\n",
    "else:\n",
    "    print(\"Skipping visual display due to earlier errors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514c384-9791-4c78-af1b-f1961ff4f4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FINAL",
   "language": "python",
   "name": "final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
