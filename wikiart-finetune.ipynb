{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a267363-a00b-4b89-a5b8-74f575fb5ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Defining helper functions...\n",
      "\n",
      "Step 1: Loading and preparing the WikiArt dataset (all classes)...\n",
      "Found 28 classes in the dataset.\n",
      "  Found 2782 images for class 'Abstract_Expressionism'.\n",
      "  Found 98 images for class 'Action_painting'.\n",
      "  Found 110 images for class 'Analytical_Cubism'.\n",
      "  Found 4334 images for class 'Art_Nouveau_Modern'.\n",
      "  Found 4240 images for class 'Baroque'.\n",
      "  Found 1615 images for class 'Color_Field_Painting'.\n",
      "  Found 481 images for class 'Contemporary_Realism'.\n",
      "  Found 2235 images for class 'Cubism'.\n",
      "  Found 1391 images for class 'Early_Renaissance'.\n",
      "  Found 6736 images for class 'Expressionism'.\n",
      "  Found 934 images for class 'Fauvism'.\n",
      "  Found 1343 images for class 'High_Renaissance'.\n",
      "  Found 13060 images for class 'Impressionism'.\n",
      "  Found 1279 images for class 'Mannerism_Late_Renaissance'.\n",
      "  Found 1337 images for class 'Minimalism'.\n",
      "  Found 2405 images for class 'Naive_Art_Primitivism'.\n",
      "  Found 314 images for class 'New_Realism'.\n",
      "  Found 2552 images for class 'Northern_Renaissance'.\n",
      "  Found 513 images for class 'Pointillism'.\n",
      "  Found 1483 images for class 'Pop_Art'.\n",
      "  Found 6450 images for class 'Post_Impressionism'.\n",
      "  Found 10733 images for class 'Realism'.\n",
      "  Found 2089 images for class 'Rococo'.\n",
      "  Found 7019 images for class 'Romanticism'.\n",
      "  Found 4528 images for class 'Symbolism'.\n",
      "  Found 216 images for class 'Synthetic_Cubism'.\n",
      "  Found 1167 images for class 'Ukiyo_e'.\n",
      "  Found 118667 images for class 'art_images'.\n",
      "Prepared image_df with 200111 entries from all classes.\n",
      "\n",
      "Step 2: Defining image transformations...\n",
      "Image transformations defined.\n",
      "\n",
      "Step 3: Creating custom dataset and data loader...\n",
      "DataLoader created with 12507 batches.\n",
      "\n",
      "Step 4: Setting up the device and loading the pre-trained model...\n",
      "Using device: cuda\n",
      "Pre-trained model loaded and modified for feature extraction.\n",
      "\n",
      "Step 5: Extracting features from all images...\n",
      "Feature file 'wikiart_features.npy' found. Loading existing features...\n",
      "Loaded features with shape: (200111, 2048)\n",
      "\n",
      "Step 6: Creating FAISS index with extracted features...\n",
      "Feature dimension: 2048\n",
      "FAISS IndexFlatIP created.\n",
      "Added 200111 features to the FAISS index.\n",
      "FAISS index saved to 'wikiart_faiss_index.bin'.\n",
      "\n",
      "Step 7: Performing queries on user-specified images...\n",
      "\n",
      "Query 1/1\n",
      "Selected image for querying: starry.png\n",
      "\n",
      "Identifying artwork...\n",
      "  Processing input image: starry.png\n",
      "  Image processed and transformed.\n",
      "  Extracting features from the query image...\n",
      "  Features extracted and normalized.\n",
      "  Searching for top 5 similar artworks...\n",
      "  Search completed.\n",
      "  Retrieving artwork information for the top matches...\n",
      "  Artwork information retrieved.\n",
      "Artwork identification completed.\n",
      "\n",
      "Top matching artworks for Query 1:\n",
      "Rank 1:\n",
      "  Label: Post_Impressionism\n",
      "  Similarity Score: 0.8915\n",
      "  Image Path: ../../scratch/mexas.v/Post_Impressionism/vincent-van-gogh_the-starry-night-1889(1).jpg\n",
      "\n",
      "Rank 2:\n",
      "  Label: Expressionism\n",
      "  Similarity Score: 0.8174\n",
      "  Image Path: ../../scratch/mexas.v/Expressionism/johannes-sveinsson-kjarval_amazon-woman-of-the-mountain-1961.jpg\n",
      "\n",
      "Rank 3:\n",
      "  Label: Fauvism\n",
      "  Similarity Score: 0.8132\n",
      "  Image Path: ../../scratch/mexas.v/Fauvism/raoul-dufy_still-life-with-bananas-1909.jpg\n",
      "\n",
      "Rank 4:\n",
      "  Label: Post_Impressionism\n",
      "  Similarity Score: 0.8124\n",
      "  Image Path: ../../scratch/mexas.v/Post_Impressionism/vincent-van-gogh_olive-trees-against-a-slope-of-a-hill-1889.jpg\n",
      "\n",
      "Rank 5:\n",
      "  Label: Fauvism\n",
      "  Similarity Score: 0.8027\n",
      "  Image Path: ../../scratch/mexas.v/Fauvism/ilya-mashkov_portrait-of-v-p-vinogradova-1909.jpg\n",
      "\n",
      "\n",
      "Displaying results visually...\n",
      "Loaded Match 1: ../../scratch/mexas.v/Post_Impressionism/vincent-van-gogh_the-starry-night-1889(1).jpg\n",
      "Loaded Match 2: ../../scratch/mexas.v/Expressionism/johannes-sveinsson-kjarval_amazon-woman-of-the-mountain-1961.jpg\n",
      "Loaded Match 3: ../../scratch/mexas.v/Fauvism/raoul-dufy_still-life-with-bananas-1909.jpg\n",
      "Loaded Match 4: ../../scratch/mexas.v/Post_Impressionism/vincent-van-gogh_olive-trees-against-a-slope-of-a-hill-1889.jpg\n",
      "Loaded Match 5: ../../scratch/mexas.v/Fauvism/ilya-mashkov_portrait-of-v-p-vinogradova-1909.jpg\n",
      "Results displayed and saved to 'results/query_results_1.png'.\n",
      "Query 1 result: Top match is not the query image (query image not in dataset)\n",
      "\n",
      "Summary:\n",
      "Total Queries: 1\n",
      "Valid Queries (Images in Dataset): 0\n",
      "Correct Matches: 0\n",
      "No valid queries (no query images were found in the dataset).\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use a non-interactive backend suitable for script running\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # For progress bars\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import faiss\n",
    "\n",
    "# Additional imports for label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import traceback for detailed error messages\n",
    "import traceback\n",
    "\n",
    "# Step 0: Define Helper Functions\n",
    "print(\"Step 0: Defining helper functions...\")\n",
    "\n",
    "def show_results(query_image_path, results, query_index, transformed=False):\n",
    "    \"\"\"\n",
    "    Displays the query image alongside its top matching results and saves the figure.\n",
    "\n",
    "    Parameters:\n",
    "    - query_image_path (str): Path or URL of the query image.\n",
    "    - results (pd.DataFrame): DataFrame containing the top matching artworks.\n",
    "    - query_index (int): Index of the query image.\n",
    "    - transformed (bool): Indicates if the query image was transformed.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    print(\"\\nDisplaying results visually...\")\n",
    "    try:\n",
    "        if query_image_path.startswith('http'):\n",
    "            response = requests.get(query_image_path, timeout=10)\n",
    "            query_img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        else:\n",
    "            query_img = Image.open(query_image_path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load query image: {e}\")\n",
    "        return\n",
    "\n",
    "    if transformed:\n",
    "        # Visual indication that the query image was transformed\n",
    "        query_img = query_img.filter(ImageFilter.GaussianBlur(radius=1))\n",
    "        query_img = query_img.rotate(10)  # Example transformation\n",
    "\n",
    "    num_results = min(len(results), 5)\n",
    "    plt.figure(figsize=(5 * (num_results + 1), 5))\n",
    "\n",
    "    # Display Query Image\n",
    "    plt.subplot(1, num_results + 1, 1)\n",
    "    plt.imshow(query_img)\n",
    "    title = 'Query Image'\n",
    "    if transformed:\n",
    "        title += ' (Transformed)'\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display Matching Images\n",
    "    for i in range(num_results):\n",
    "        img_path = results.iloc[i]['image_path']\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            plt.subplot(1, num_results + 1, i + 2)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Match {i+1}\")\n",
    "            plt.axis('off')\n",
    "            print(f\"Loaded Match {i+1}: {img_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load image {img_path}: {e}\")\n",
    "\n",
    "    output_dir = 'results'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_path = os.path.join(output_dir, f'query_results_{query_index}.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\"Results displayed and saved to '{output_path}'.\")\n",
    "\n",
    "def process_input_image(image_path_or_url, transform, device):\n",
    "    \"\"\"\n",
    "    Processes the input image by loading, transforming, and sending it to the device.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path_or_url (str): Path or URL of the image.\n",
    "    - transform (torchvision.transforms.Compose): Transformations to apply.\n",
    "    - device (torch.device): Device to send the image tensor.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Processed image tensor.\n",
    "    \"\"\"\n",
    "    print(f\"  Processing input image: {image_path_or_url}\")\n",
    "    try:\n",
    "        if image_path_or_url.startswith('http'):\n",
    "            response = requests.get(image_path_or_url, timeout=10)\n",
    "            img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        else:\n",
    "            img = Image.open(image_path_or_url).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to load image {image_path_or_url}: {e}\")\n",
    "        # Return a black image in case of error\n",
    "        img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "    try:\n",
    "        img = transform(img).unsqueeze(0).to(device, non_blocking=True)\n",
    "        print(\"  Image processed and transformed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to transform image {image_path_or_url}: {e}\")\n",
    "        # Return a tensor of zeros in case of transformation failure\n",
    "        img = torch.zeros((1, 3, 224, 224)).to(device)\n",
    "    return img\n",
    "\n",
    "def get_image_features(model, img_tensor):\n",
    "    \"\"\"\n",
    "    Extracts and normalizes features from the image tensor.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The feature extraction model.\n",
    "    - img_tensor (torch.Tensor): Image tensor.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Normalized feature vector.\n",
    "    \"\"\"\n",
    "    print(\"  Extracting features from the query image...\")\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            features = model(img_tensor)\n",
    "            features = features.view(features.size(0), -1)  # Flatten\n",
    "            features = features / features.norm(dim=1, keepdim=True)\n",
    "        print(\"  Features extracted and normalized.\")\n",
    "        return features.cpu().numpy().astype('float32')\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to extract features: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def search_artwork(query_features, index, k=5):\n",
    "    \"\"\"\n",
    "    Searches for the top k similar artworks using FAISS.\n",
    "\n",
    "    Parameters:\n",
    "    - query_features (np.ndarray): Feature vector of the query image.\n",
    "    - index (faiss.Index): FAISS index.\n",
    "    - k (int): Number of top matches to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - distances (np.ndarray): Similarity scores.\n",
    "    - indices (np.ndarray): Indices of the top matches.\n",
    "    \"\"\"\n",
    "    print(f\"  Searching for top {k} similar artworks...\")\n",
    "    try:\n",
    "        distances, indices = index.search(query_features, k)\n",
    "        print(\"  Search completed.\")\n",
    "        return distances[0], indices[0]\n",
    "    except Exception as e:\n",
    "        print(f\"  FAISS search failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def get_artwork_info(indices, image_df):\n",
    "    \"\"\"\n",
    "    Retrieves artwork information based on the indices.\n",
    "\n",
    "    Parameters:\n",
    "    - indices (np.ndarray): Indices of the top matches.\n",
    "    - image_df (pd.DataFrame): DataFrame containing image metadata.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame of the top matching artworks.\n",
    "    \"\"\"\n",
    "    print(\"  Retrieving artwork information for the top matches...\")\n",
    "    try:\n",
    "        results = image_df.iloc[indices].reset_index(drop=True)\n",
    "        print(\"  Artwork information retrieved.\")\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"  Error retrieving artwork information: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return pd.DataFrame()  # Return empty DataFrame on error\n",
    "\n",
    "def identify_artwork(image_path_or_url, model, index, image_df, transform, device, k=5):\n",
    "    \"\"\"\n",
    "    Identifies the top k artworks similar to the query image.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path_or_url (str): Path or URL of the query image.\n",
    "    - model (torch.nn.Module): Feature extraction model.\n",
    "    - index (faiss.Index): FAISS index.\n",
    "    - image_df (pd.DataFrame): DataFrame containing image metadata.\n",
    "    - transform (torchvision.transforms.Compose): Transformations to apply.\n",
    "    - device (torch.device): Device to send the image tensor.\n",
    "    - k (int): Number of top matches to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - results (pd.DataFrame): DataFrame of the top matching artworks.\n",
    "    - distances (np.ndarray): Similarity scores.\n",
    "    \"\"\"\n",
    "    print(\"\\nIdentifying artwork...\")\n",
    "    img_tensor = process_input_image(image_path_or_url, transform, device)\n",
    "    if img_tensor is None:\n",
    "        print(\"  Image tensor is None. Skipping identification.\")\n",
    "        return pd.DataFrame(), np.array([])\n",
    "    \n",
    "    query_features = get_image_features(model, img_tensor)\n",
    "    if query_features is None:\n",
    "        print(\"  Query features are None. Skipping identification.\")\n",
    "        return pd.DataFrame(), np.array([])\n",
    "    \n",
    "    distances, indices = search_artwork(query_features, index, k)\n",
    "    if indices is None:\n",
    "        print(\"  Indices are None. Skipping retrieval.\")\n",
    "        return pd.DataFrame(), np.array([])\n",
    "    \n",
    "    results = get_artwork_info(indices, image_df)\n",
    "    print(\"Artwork identification completed.\")\n",
    "    return results, distances\n",
    "\n",
    "def extract_features(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Extracts features from images using the provided model and dataloader.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The feature extraction model.\n",
    "    - dataloader (DataLoader): DataLoader for the dataset.\n",
    "    - device (torch.device): Device to perform computations on.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Extracted features.\n",
    "    \"\"\"\n",
    "    print(\"Starting feature extraction...\")\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (imgs, _) in enumerate(tqdm(dataloader, desc=\"Extracting features\"), 1):\n",
    "            try:\n",
    "                imgs = imgs.to(device, non_blocking=True)\n",
    "                outputs = model(imgs)\n",
    "                outputs = outputs.view(outputs.size(0), -1)  # Flatten to (batch_size, feature_dim)\n",
    "                outputs = outputs / outputs.norm(dim=1, keepdim=True)\n",
    "                features.append(outputs.cpu())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch {batch_idx}: {e}\")\n",
    "                traceback.print_exc()\n",
    "    if features:\n",
    "        features = torch.cat(features, dim=0)\n",
    "    else:\n",
    "        features = torch.tensor([])\n",
    "    print(\"Feature extraction completed.\")\n",
    "    return features\n",
    "\n",
    "# Step 1: Load and Prepare the WikiArt Dataset (All Classes)\n",
    "print(\"\\nStep 1: Loading and preparing the WikiArt dataset (all classes)...\")\n",
    "\n",
    "# Specify the path to the WikiArt dataset\n",
    "wikiart_dir = '../../scratch/mexas.v'  # Update this path as necessary\n",
    "\n",
    "# Check if the dataset directory exists\n",
    "if not os.path.exists(wikiart_dir):\n",
    "    raise FileNotFoundError(f\"WikiArt directory '{wikiart_dir}' does not exist. Please update the path.\")\n",
    "\n",
    "# Get the list of class names (styles, artists, or genres)\n",
    "classes = [d for d in os.listdir(wikiart_dir) if os.path.isdir(os.path.join(wikiart_dir, d))]\n",
    "print(f\"Found {len(classes)} classes in the dataset.\")\n",
    "\n",
    "# Prepare a list to hold image paths and labels\n",
    "data = []\n",
    "\n",
    "for label in classes:\n",
    "    # Get all image paths for the current class\n",
    "    image_paths = glob.glob(os.path.join(wikiart_dir, label, '*.jpg'))\n",
    "    print(f\"  Found {len(image_paths)} images for class '{label}'.\")\n",
    "    for path in image_paths:\n",
    "        data.append({\n",
    "            'image_path': path,\n",
    "            'label': label\n",
    "        })\n",
    "\n",
    "# Create a DataFrame\n",
    "image_df = pd.DataFrame(data)\n",
    "print(f\"Prepared image_df with {len(image_df)} entries from all classes.\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "image_df['encoded_label'] = label_encoder.fit_transform(image_df['label'])\n",
    "\n",
    "# Step 2: Define Image Transformations\n",
    "print(\"\\nStep 2: Defining image transformations...\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "print(\"Image transformations defined.\")\n",
    "\n",
    "# Step 3: Create Custom Dataset and DataLoader\n",
    "print(\"\\nStep 3: Creating custom dataset and data loader...\")\n",
    "\n",
    "class ArtImageDataset(Dataset):\n",
    "    def __init__(self, image_df, transform=None):\n",
    "        self.image_df = image_df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_df.loc[idx, 'image_path']\n",
    "        label = self.image_df.loc[idx, 'encoded_label']\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        if self.transform:\n",
    "            try:\n",
    "                img = self.transform(img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error transforming image {img_path}: {e}\")\n",
    "                img = torch.zeros((3, 224, 224))  # Fallback to a tensor of zeros\n",
    "        return img, idx  # Return index to keep track\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "batch_size = 16  # Adjust based on your GPU memory\n",
    "dataset = ArtImageDataset(image_df, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=12, pin_memory=True)\n",
    "\n",
    "print(f\"DataLoader created with {len(dataloader)} batches.\")\n",
    "\n",
    "# Step 4: Set Up Device and Load Pre-trained Model\n",
    "print(\"\\nStep 4: Setting up the device and loading the pre-trained model...\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the pre-trained ResNet-50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Remove the final classification layer for feature extraction\n",
    "model = nn.Sequential(*list(model.children())[:-1])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Pre-trained model loaded and modified for feature extraction.\")\n",
    "# Step 5: Extract Features with Conditional Loading\n",
    "print(\"\\nStep 5: Extracting features from all images...\")\n",
    "\n",
    "# Define the path to save/load features\n",
    "features_file = 'wikiart_features.npy'\n",
    "\n",
    "if os.path.exists(features_file):\n",
    "    print(f\"Feature file '{features_file}' found. Loading existing features...\")\n",
    "    try:\n",
    "        features_np = np.load(features_file)\n",
    "        print(f\"Loaded features with shape: {features_np.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading features from '{features_file}': {e}\")\n",
    "        traceback.print_exc()\n",
    "        print(\"Proceeding to extract features anew.\")\n",
    "        \n",
    "        # Extract features as the file could not be loaded\n",
    "        features = extract_features(model, dataloader, device)\n",
    "        print(f\"Extracted features shape: {features.shape}\")\n",
    "        \n",
    "        if features.numel() > 0:\n",
    "            # Convert features to numpy array\n",
    "            features_np = features.cpu().numpy().astype('float32')\n",
    "            \n",
    "            # Save features\n",
    "            np.save(features_file, features_np)\n",
    "            print(f\"Features extracted and saved to '{features_file}'.\")\n",
    "        else:\n",
    "            print(\"No features extracted. Exiting.\")\n",
    "            exit(1)\n",
    "else:\n",
    "    print(f\"Feature file '{features_file}' not found. Extracting features...\")\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(model, dataloader, device)\n",
    "    print(f\"Extracted features shape: {features.shape}\")\n",
    "    \n",
    "    if features.numel() > 0:\n",
    "        # Convert features to numpy array\n",
    "        features_np = features.cpu().numpy().astype('float32')\n",
    "        \n",
    "        # Save features\n",
    "        np.save(features_file, features_np)\n",
    "        print(f\"Features extracted and saved to '{features_file}'.\")\n",
    "    else:\n",
    "        print(\"No features extracted. Exiting.\")\n",
    "        exit(1)\n",
    "\n",
    "# Step 6: Create FAISS Index and Add Features\n",
    "print(\"\\nStep 6: Creating FAISS index with extracted features...\")\n",
    "\n",
    "# Verify that feature dimensions match\n",
    "feature_dim = features_np.shape[1]\n",
    "print(f\"Feature dimension: {feature_dim}\")\n",
    "\n",
    "try:\n",
    "    # Create FAISS index for Inner Product (cosine similarity if features are normalized)\n",
    "    index = faiss.IndexFlatIP(feature_dim)\n",
    "    print(\"FAISS IndexFlatIP created.\")\n",
    "    \n",
    "    # Add features to the index\n",
    "    index.add(features_np)\n",
    "    print(f\"Added {index.ntotal} features to the FAISS index.\")\n",
    "    \n",
    "    # Save the FAISS index\n",
    "    faiss_index_path = 'wikiart_faiss_index.bin'\n",
    "    faiss.write_index(index, faiss_index_path)\n",
    "    print(f\"FAISS index saved to '{faiss_index_path}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create or save FAISS index: {e}\")\n",
    "    traceback.print_exc()\n",
    "    exit(1)\n",
    "\n",
    "# # Step 7: Perform Queries on 100 Random Obfuscated Images\n",
    "# print(\"\\nStep 7: Performing queries on 100 random obfuscated images...\")\n",
    "\n",
    "# num_queries = 100  # Number of random images to query\n",
    "# k = 5  # Number of top matches to retrieve\n",
    "\n",
    "# # Ensure the dataset has enough images\n",
    "# if num_queries > len(image_df):\n",
    "#     num_queries = len(image_df)\n",
    "#     print(f\"Only {num_queries} images available. Adjusting number of queries to {num_queries}.\")\n",
    "\n",
    "# # Select 100 random indices from the dataset\n",
    "# random_indices = random.sample(range(len(image_df)), num_queries)\n",
    "\n",
    "# # Initialize counters\n",
    "# correct_at_1 = 0  # Top-1 accuracy\n",
    "# correct_at_k = 0  # Top-k accuracy\n",
    "\n",
    "# # Directory to save transformed query images\n",
    "# transformed_dir = 'transformed_queries'\n",
    "# if not os.path.exists(transformed_dir):\n",
    "#     os.makedirs(transformed_dir)\n",
    "\n",
    "# for idx, query_image_index in enumerate(tqdm(random_indices, desc=\"Processing Queries\"), 1):\n",
    "#     print(f\"\\nQuery {idx}/{num_queries}\")\n",
    "#     original_image_path = image_df.iloc[query_image_index]['image_path']\n",
    "#     original_label = image_df.iloc[query_image_index]['encoded_label']\n",
    "#     image_filename = os.path.basename(original_image_path)\n",
    "#     transformed_image_path = os.path.join(transformed_dir, f\"transformed_{image_filename}\")\n",
    "    \n",
    "#     # Apply obfuscations: rotation and blur\n",
    "#     try:\n",
    "#         img = Image.open(original_image_path).convert('RGB')\n",
    "#         # Random rotation between -15 and +15 degrees\n",
    "#         rotation_angle = random.uniform(-15, 15)\n",
    "#         img = img.rotate(rotation_angle)\n",
    "#         # Random Gaussian blur with radius between 0 and 2\n",
    "#         blur_radius = random.uniform(0, 2)\n",
    "#         img = img.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "#         img.save(transformed_image_path)\n",
    "#         print(f\"  Applied rotation of {rotation_angle:.2f} degrees and blur radius of {blur_radius:.2f}.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"  Error transforming image {original_image_path}: {e}\")\n",
    "#         traceback.print_exc()\n",
    "#         continue\n",
    "    \n",
    "#     # Perform retrieval using the obfuscated image\n",
    "#     try:\n",
    "#         results, distances = identify_artwork(\n",
    "#             transformed_image_path,\n",
    "#             model,\n",
    "#             index,\n",
    "#             image_df,\n",
    "#             transform,\n",
    "#             device,\n",
    "#             k=k\n",
    "#         )\n",
    "        \n",
    "#         if results.empty or distances.size == 0:\n",
    "#             print(f\"  No results returned for query {idx}. Skipping accuracy checks.\")\n",
    "#             continue\n",
    "#     except Exception as e:\n",
    "#         print(f\"  Error identifying artwork for {transformed_image_path}: {e}\")\n",
    "#         traceback.print_exc()\n",
    "#         continue\n",
    "    \n",
    "#     # Check if the correct match is in the top k\n",
    "#     retrieved_labels = results['encoded_label'].values\n",
    "#     retrieved_image_paths = results['image_path'].values\n",
    "    \n",
    "#     # Check for Top-1 accuracy\n",
    "#     if retrieved_labels[0] == original_label:\n",
    "#         correct_at_1 += 1\n",
    "    \n",
    "#     # Check for Top-k accuracy\n",
    "#     if original_label in retrieved_labels:\n",
    "#         correct_at_k += 1\n",
    "    \n",
    "#     # Display and save results\n",
    "#     show_results(transformed_image_path, results, query_index=idx, transformed=True)\n",
    "\n",
    "# # Step 8: Summary of Evaluation Results\n",
    "# print(\"\\nStep 8: Summary of Evaluation Results:\")\n",
    "# print(f\"Total Queries: {num_queries}\")\n",
    "# print(f\"Top-1 Correct Matches: {correct_at_1}\")\n",
    "# print(f\"Top-{k} Correct Matches: {correct_at_k}\")\n",
    "# if num_queries > 0:\n",
    "#     top1_accuracy = (correct_at_1 / num_queries) * 100\n",
    "#     topk_accuracy = (correct_at_k / num_queries) * 100\n",
    "#     print(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")\n",
    "#     print(f\"Top-{k} Accuracy: {topk_accuracy:.2f}%\")\n",
    "# else:\n",
    "#     print(\"No valid queries were performed.\")\n",
    "\n",
    "\n",
    "# Step 7: Perform Queries on User-Specified Images\n",
    "print(\"\\nStep 7: Performing queries on user-specified images...\")\n",
    "\n",
    "# Define a list of images to query\n",
    "# You can add image paths or URLs to this list\n",
    "query_images = [\n",
    "    \"starry.png\",\n",
    "]\n",
    "\n",
    "correct_matches = 0  # Counter for correct matches\n",
    "valid_queries = 0    # Counter for queries where the image is in the dataset\n",
    "\n",
    "for idx, image_to_query in enumerate(query_images, 1):\n",
    "    print(f\"\\nQuery {idx}/{len(query_images)}\")\n",
    "    print(f\"Selected image for querying: {image_to_query}\")\n",
    "\n",
    "    try:\n",
    "        # Use the existing identify_artwork function to get results\n",
    "        results, distances = identify_artwork(\n",
    "            image_to_query,\n",
    "            model,\n",
    "            index,\n",
    "            image_df,\n",
    "            transform,\n",
    "            device,\n",
    "            k=5\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying artwork: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Check if the query image is part of the dataset\n",
    "    is_in_dataset = image_to_query in image_df['image_path'].values\n",
    "\n",
    "    if is_in_dataset:\n",
    "        valid_queries += 1\n",
    "        # Retrieve the top match image path\n",
    "        top_match_image_path = results.iloc[0]['image_path']\n",
    "        if top_match_image_path == image_to_query:\n",
    "            correct_matches += 1\n",
    "            match_status = \"Correct Match\"\n",
    "        else:\n",
    "            match_status = \"Incorrect Match\"\n",
    "    else:\n",
    "        match_status = \"Top match is not the query image (query image not in dataset)\"\n",
    "\n",
    "    # Display Top Matching Artworks\n",
    "    print(f\"\\nTop matching artworks for Query {idx}:\")\n",
    "    for i, (result_idx, dist) in enumerate(zip(results.index, distances)):\n",
    "        row = results.iloc[i]\n",
    "        print(f\"Rank {i+1}:\")\n",
    "        print(f\"  Label: {row['label']}\")\n",
    "        print(f\"  Similarity Score: {dist:.4f}\")\n",
    "        print(f\"  Image Path: {row['image_path']}\\n\")\n",
    "\n",
    "    # Display and save results\n",
    "    show_results(image_to_query, results, query_index=idx)\n",
    "\n",
    "    print(f\"Query {idx} result: {match_status}\")\n",
    "\n",
    "# Step 8: Print Summary Statistics\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total Queries: {len(query_images)}\")\n",
    "print(f\"Valid Queries (Images in Dataset): {valid_queries}\")\n",
    "print(f\"Correct Matches: {correct_matches}\")\n",
    "if valid_queries > 0:\n",
    "    accuracy = (correct_matches / valid_queries) * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "else:\n",
    "    print(\"No valid queries (no query images were found in the dataset).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709761c-3915-4ec0-b17e-aa253dc469d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3f8f3-562e-48bc-aa21-eaa94715f2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034c0b07-70ef-40f9-a6ce-d4c61b2ba2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FINAL",
   "language": "python",
   "name": "final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
