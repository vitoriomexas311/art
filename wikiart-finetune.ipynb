{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a267363-a00b-4b89-a5b8-74f575fb5ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Defining helper functions...\n",
      "\n",
      "Step 1: Loading and preparing the WikiArt dataset (Impressionism only)...\n",
      "Prepared image_df with 13060 entries from class 'Impressionism'.\n",
      "\n",
      "Step 2: Defining image transformations...\n",
      "Image transformations defined.\n",
      "\n",
      "Step 3: Creating custom dataset and data loader...\n",
      "DataLoader created with 409 batches.\n",
      "\n",
      "Step 4: Setting up the device and loading the pre-trained model...\n",
      "Using device: cuda\n",
      "Pre-trained model loaded and modified for feature extraction.\n",
      "\n",
      "Step 5: Extracting features from all images...\n",
      "Starting feature extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|███████   | 288/409 [07:51<00:50,  2.39it/s]"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use a non-interactive backend suitable for script running\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # For progress bars\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import faiss\n",
    "\n",
    "# Additional imports for label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 0: Define Helper Functions\n",
    "print(\"Step 0: Defining helper functions...\")\n",
    "\n",
    "def show_results(image_path_or_url, results, query_index):\n",
    "    \"\"\"\n",
    "    Displays the query image alongside its top matching results and saves the figure.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path_or_url (str): Path or URL of the query image.\n",
    "    - results (pd.DataFrame): DataFrame containing the top matching artworks.\n",
    "    - query_index (int): Index of the query image.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    print(\"\\nDisplaying results visually...\")\n",
    "    try:\n",
    "        if image_path_or_url.startswith('http'):\n",
    "            response = requests.get(image_path_or_url, timeout=10)\n",
    "            query_img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        else:\n",
    "            query_img = Image.open(image_path_or_url).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load query image: {e}\")\n",
    "        return\n",
    "\n",
    "    num_results = min(len(results), 5)\n",
    "    plt.figure(figsize=(5 * (num_results + 1), 5))\n",
    "\n",
    "    # Display Query Image\n",
    "    plt.subplot(1, num_results + 1, 1)\n",
    "    plt.imshow(query_img)\n",
    "    plt.title('Query Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display Matching Images\n",
    "    for i in range(num_results):\n",
    "        img_path = results.iloc[i]['image_path']\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            plt.subplot(1, num_results + 1, i + 2)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Match {i+1}\")\n",
    "            plt.axis('off')\n",
    "            print(f\"Loaded Match {i+1}: {img_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load image {img_path}: {e}\")\n",
    "\n",
    "    output_dir = 'results'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_path = os.path.join(output_dir, f'query_results_{query_index}.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\"Results displayed and saved to '{output_path}'.\")\n",
    "\n",
    "def process_input_image(image_path_or_url, transform, device):\n",
    "    \"\"\"\n",
    "    Processes the input image by loading, transforming, and sending it to the device.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path_or_url (str): Path or URL of the image.\n",
    "    - transform (torchvision.transforms.Compose): Transformations to apply.\n",
    "    - device (torch.device): Device to send the image tensor.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Processed image tensor.\n",
    "    \"\"\"\n",
    "    print(f\"  Processing input image: {image_path_or_url}\")\n",
    "    try:\n",
    "        if image_path_or_url.startswith('http'):\n",
    "            response = requests.get(image_path_or_url, timeout=10)\n",
    "            img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        else:\n",
    "            img = Image.open(image_path_or_url).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to load image {image_path_or_url}: {e}\")\n",
    "        # Return a black image in case of error\n",
    "        img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "    print(\"  Image processed and transformed.\")\n",
    "    return img\n",
    "\n",
    "def get_image_features(model, img_tensor):\n",
    "    \"\"\"\n",
    "    Extracts and normalizes features from the image tensor.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The feature extraction model.\n",
    "    - img_tensor (torch.Tensor): Image tensor.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Normalized feature vector.\n",
    "    \"\"\"\n",
    "    print(\"  Extracting features from the query image...\")\n",
    "    with torch.no_grad():\n",
    "        features = model(img_tensor)\n",
    "        features = features.view(features.size(0), -1)  # Flatten\n",
    "        features = features / features.norm(dim=1, keepdim=True)\n",
    "    print(\"  Features extracted and normalized.\")\n",
    "    return features.cpu().numpy().astype('float32')\n",
    "\n",
    "def search_artwork(query_features, index, k=5):\n",
    "    \"\"\"\n",
    "    Searches for the top k similar artworks using FAISS.\n",
    "\n",
    "    Parameters:\n",
    "    - query_features (np.ndarray): Feature vector of the query image.\n",
    "    - index (faiss.Index): FAISS index.\n",
    "    - k (int): Number of top matches to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - distances (np.ndarray): Similarity scores.\n",
    "    - indices (np.ndarray): Indices of the top matches.\n",
    "    \"\"\"\n",
    "    print(f\"  Searching for top {k} similar artworks...\")\n",
    "    distances, indices = index.search(query_features, k)\n",
    "    print(\"  Search completed.\")\n",
    "    return distances[0], indices[0]\n",
    "\n",
    "def get_artwork_info(indices, image_df):\n",
    "    \"\"\"\n",
    "    Retrieves artwork information based on the indices.\n",
    "\n",
    "    Parameters:\n",
    "    - indices (np.ndarray): Indices of the top matches.\n",
    "    - image_df (pd.DataFrame): DataFrame containing image metadata.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame of the top matching artworks.\n",
    "    \"\"\"\n",
    "    print(\"  Retrieving artwork information for the top matches...\")\n",
    "    try:\n",
    "        results = image_df.iloc[indices].reset_index(drop=True)\n",
    "        print(\"  Artwork information retrieved.\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error retrieving artwork information: {e}\")\n",
    "        results = pd.DataFrame()  # Return empty DataFrame on error\n",
    "    return results\n",
    "\n",
    "def identify_artwork(image_path_or_url, model, index, image_df, transform, device, k=5):\n",
    "    \"\"\"\n",
    "    Identifies the top k artworks similar to the query image.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path_or_url (str): Path or URL of the query image.\n",
    "    - model (torch.nn.Module): Feature extraction model.\n",
    "    - index (faiss.Index): FAISS index.\n",
    "    - image_df (pd.DataFrame): DataFrame containing image metadata.\n",
    "    - transform (torchvision.transforms.Compose): Transformations to apply.\n",
    "    - device (torch.device): Device to send the image tensor.\n",
    "    - k (int): Number of top matches to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - results (pd.DataFrame): DataFrame of the top matching artworks.\n",
    "    - distances (np.ndarray): Similarity scores.\n",
    "    \"\"\"\n",
    "    print(\"\\nIdentifying artwork...\")\n",
    "    img_tensor = process_input_image(image_path_or_url, transform, device)\n",
    "    query_features = get_image_features(model, img_tensor)\n",
    "    distances, indices = search_artwork(query_features, index, k)\n",
    "    results = get_artwork_info(indices, image_df)\n",
    "    print(\"Artwork identification completed.\")\n",
    "    return results, distances\n",
    "\n",
    "def extract_features(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Extracts features from images using the provided model and dataloader.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The feature extraction model.\n",
    "    - dataloader (DataLoader): DataLoader for the dataset.\n",
    "    - device (torch.device): Device to perform computations on.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Extracted features.\n",
    "    \"\"\"\n",
    "    print(\"Starting feature extraction...\")\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (imgs, _) in enumerate(tqdm(dataloader, desc=\"Extracting features\"), 1):\n",
    "            imgs = imgs.to(device)\n",
    "            try:\n",
    "                outputs = model(imgs)\n",
    "                outputs = outputs.view(outputs.size(0), -1)  # Flatten to (batch_size, feature_dim)\n",
    "                outputs = outputs / outputs.norm(dim=1, keepdim=True)\n",
    "                features.append(outputs.cpu())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch {batch_idx}: {e}\")\n",
    "    features = torch.cat(features, dim=0)\n",
    "    print(\"Feature extraction completed.\")\n",
    "    return features\n",
    "\n",
    "# Step 1: Load and Prepare the WikiArt Dataset (Impressionism Only)\n",
    "print(\"\\nStep 1: Loading and preparing the WikiArt dataset (Impressionism only)...\")\n",
    "\n",
    "# Specify the path to the WikiArt dataset\n",
    "wikiart_dir = '../../scratch/mexas.v'\n",
    "\n",
    "# Only use the 'Impressionism' folder\n",
    "selected_class = 'Impressionism'\n",
    "\n",
    "# Verify that the folder exists\n",
    "class_path = os.path.join(wikiart_dir, selected_class)\n",
    "if not os.path.exists(class_path):\n",
    "    print(f\"Class folder '{selected_class}' not found in '{wikiart_dir}'.\")\n",
    "    exit(1)\n",
    "\n",
    "# Prepare a list to hold image paths and labels\n",
    "data = []\n",
    "\n",
    "# Get all image paths for the selected class\n",
    "image_paths = glob.glob(os.path.join(class_path, '*.jpg'))\n",
    "for path in image_paths:\n",
    "    data.append({\n",
    "        'image_path': path,\n",
    "        'label': selected_class\n",
    "    })\n",
    "\n",
    "# Create a DataFrame\n",
    "image_df = pd.DataFrame(data)\n",
    "print(f\"Prepared image_df with {len(image_df)} entries from class '{selected_class}'.\")\n",
    "\n",
    "# Encode labels (though we have only one class here)\n",
    "label_encoder = LabelEncoder()\n",
    "image_df['encoded_label'] = label_encoder.fit_transform(image_df['label'])\n",
    "\n",
    "# Step 2: Define Image Transformations\n",
    "print(\"\\nStep 2: Defining image transformations...\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "print(\"Image transformations defined.\")\n",
    "\n",
    "# Step 3: Create Custom Dataset and DataLoader\n",
    "print(\"\\nStep 3: Creating custom dataset and data loader...\")\n",
    "\n",
    "class ArtImageDataset(Dataset):\n",
    "    def __init__(self, image_df, transform=None):\n",
    "        self.image_df = image_df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_df.loc[idx, 'image_path']\n",
    "        label = self.image_df.loc[idx, 'encoded_label']\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, idx  # Return index to keep track\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "batch_size = 32  # Adjust based on your GPU memory\n",
    "dataset = ArtImageDataset(image_df, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=12)\n",
    "\n",
    "print(f\"DataLoader created with {len(dataloader)} batches.\")\n",
    "\n",
    "# Step 4: Set Up Device and Load Pre-trained Model\n",
    "print(\"\\nStep 4: Setting up the device and loading the pre-trained model...\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the pre-trained ResNet-50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Remove the final classification layer for feature extraction\n",
    "model = nn.Sequential(*list(model.children())[:-1])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Pre-trained model loaded and modified for feature extraction.\")\n",
    "\n",
    "# Step 5: Extract Features\n",
    "print(\"\\nStep 5: Extracting features from all images...\")\n",
    "\n",
    "features = extract_features(model, dataloader, device)\n",
    "print(f\"Extracted features shape: {features.shape}\")\n",
    "\n",
    "# Convert features to numpy array\n",
    "features_np = features.squeeze().numpy().astype('float32')\n",
    "\n",
    "# Save features\n",
    "np.save('impressionism_features.npy', features_np)\n",
    "print(\"Features saved to 'impressionism_features.npy'.\")\n",
    "\n",
    "# Step 6: Create FAISS Index and Add Features\n",
    "print(\"\\nStep 6: Creating FAISS index with extracted features...\")\n",
    "\n",
    "index = faiss.IndexFlatIP(features_np.shape[1])\n",
    "index.add(features_np)\n",
    "faiss.write_index(index, 'impressionism_faiss_index.bin')\n",
    "print(\"FAISS index created with extracted features and saved to 'impressionism_faiss_index.bin'.\")\n",
    "\n",
    "# Step 7: Perform Queries on Random Sample of Images\n",
    "print(\"\\nStep 7: Performing queries on a random sample of images...\")\n",
    "\n",
    "num_queries = 100  # Number of random images to query\n",
    "if num_queries > len(image_df):\n",
    "    num_queries = len(image_df)\n",
    "    print(f\"Only {num_queries} images available. Adjusting number of queries to {num_queries}.\")\n",
    "\n",
    "random_indices = random.sample(range(len(image_df)), num_queries)\n",
    "\n",
    "correct_matches = 0  # Counter for correct matches\n",
    "\n",
    "for idx, query_image_index in enumerate(random_indices):\n",
    "    print(f\"\\nQuery {idx+1}/{num_queries}\")\n",
    "    image_to_query = image_df.iloc[query_image_index]['image_path']\n",
    "    print(f\"Selected image for querying: {image_to_query}\")\n",
    "\n",
    "    try:\n",
    "        # Use the same model and FAISS index\n",
    "        results, distances = identify_artwork(\n",
    "            image_to_query,\n",
    "            model,\n",
    "            index,\n",
    "            image_df,\n",
    "            transform,\n",
    "            device,\n",
    "            k=5\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying artwork: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Check if the top match is the same as the query image\n",
    "    top_match_index = results.index[0]\n",
    "    if top_match_index == query_image_index:\n",
    "        correct_matches += 1\n",
    "        match_status = \"Correct Match\"\n",
    "    else:\n",
    "        match_status = \"Incorrect Match\"\n",
    "\n",
    "    # Display Top Matching Artworks\n",
    "    print(f\"\\nTop matching artworks for Query {idx+1}:\")\n",
    "    for i, (result_idx, dist) in enumerate(zip(results.index, distances)):\n",
    "        row = results.iloc[i]\n",
    "        print(f\"Rank {i+1}:\")\n",
    "        print(f\"  Label: {row['label']}\")\n",
    "        print(f\"  Similarity Score: {dist:.4f}\")\n",
    "        print(f\"  Image Path: {row['image_path']}\\n\")\n",
    "\n",
    "    # Display and save results\n",
    "    show_results(image_to_query, results, query_index=idx+1)\n",
    "\n",
    "    print(f\"Query {idx+1} result: {match_status}\")\n",
    "\n",
    "# Step 8: Print Summary Statistics\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total Queries: {num_queries}\")\n",
    "print(f\"Correct Matches: {correct_matches}\")\n",
    "print(f\"Accuracy: {correct_matches / num_queries * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709761c-3915-4ec0-b17e-aa253dc469d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FINAL",
   "language": "python",
   "name": "final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
